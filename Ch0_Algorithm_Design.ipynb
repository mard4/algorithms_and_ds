{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b> Algorithm <b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u> Characteristics </u>\n",
    "- It should be as specific as possible \n",
    "- It should have each instruction properly defined \n",
    "- There should not be any ambiguous instructions \n",
    "- All the instructions of the algorithm should be executable in a finite amount of time and in a finite number of steps It should have clear input and output to solve the problem \n",
    "- Each instruction of the algorithm should be integral in solving the given problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <u> Rules</u>\n",
    "1. The algorithm should be correct and should produce the results as expected for all valid input values \n",
    "2. The algorithm should be optimal in the sense that it should be executed on the computer within the desired time limit, in line with an optimal memory space requirement\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Performance analysis of an algorithm </b></center>\n",
    "is generally measured by the size of its input data, $n$, the time and the memory space used by the algorithm.\n",
    "\n",
    "The time required is measured by the <b>key operations</b> to be performed by the algorithm (such as comparison operations), where key operations are instructions that take a significant amount of time during execution.\n",
    " Whereas the space requirement of an algorithm is measured by the memory needed to store the variables, constants, and instructions during the execution of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Time Complexity </b>\n",
    "The time complexity of the algorithm is the amount of time that an algorithm will take to execute on a computer system to produce the output.\n",
    "The running time required by an algorithm depends on the input size; as the input size, $n$, increases, the runtime also increases.\n",
    "\n",
    "The runtime of an algorithm for a specific input depends on the key operations to be executed in the algorithm\n",
    "\n",
    "\n",
    "In the case below,\n",
    "The time required by the algorithm depends on the time required for each statement, and how many times a statement is executed. The running time of the algorithm is the sum of time required by all the statements.\n",
    "\n",
    "A statement is a basic operation or instruction that can be executed in constant time. n = 5 is a statement as well, however, when determining the time complexity of an algorithm, constant assignments (like initializing a variable) are often considered to be of constant time complexity because they take a fixed amount of time, regardless of the input size.\n",
    "\n",
    "\n",
    "```python\n",
    "n=5\n",
    "if n==0 | n == 3: #constant time\n",
    "    print(\"data\") \n",
    "else: \n",
    "    for i in range(#loop run for n times)\n",
    "        print(\"structure\")\n",
    "        \n",
    "# Time Required (Cost): each line of code is going to be c1,c2,c3,c4,c5\n",
    "```\n",
    "\n",
    "The total running time $T(n)$ of the algorithm for a given value of n (assuming the value of n is not zero or three) will be as follows.\n",
    "$ T(n) = c1 + c3 + c4 * n + c5 * n$\n",
    "\n",
    "If the value of n is equal to zero or three, then the time required by the algorithm will be: $T(n) = c1 + c2$\n",
    "\n",
    "In the worst case, the value of n is not equal to zero or three, then, the running time of the algorithm can be represented as $a * n + b$. Here, the values of $a$ and $b$ are constants that depend on the statement costs, and the constant times are not considered in the final time complexity. In the worst case, the runtime required by the algorithm is a linear function of $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u> Types of running time </u>\n",
    "- <b> Worst-case Running time </b> of the algorithm is the upper-bound complexity: its the maximum runtime required for an algorithm to execute for any given input\n",
    "- <b> Average-case Running time </b> is the average running time required for an algorithm to execute.\n",
    "- <b> Best-case Running time </b> is the minimum time needed for an algorithm to run; it is the lower bound on the running time required for an algorithm.\n",
    "\n",
    "\n",
    "```python\n",
    "def linear_search(input_list, element):\n",
    "    for index, value in enumerate(input_list):\n",
    "        if value == element:\n",
    "            return index \n",
    "        return -1 \n",
    "input_list = [3, 4, 1, 6, 14]\n",
    "element = 4 \n",
    "print(\"Index position for the element x is:\", linear_search(input_list, element))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the <u>linear search problem</u>, the worst case occurs when the element to be searched is found in the last comparison or not found in the list. \n",
    "\n",
    "In this case, the running time required will linearly depend upon the length of the list, whereas, in the best case, the search element will be found in the first comparison.\n",
    "In this analysis, we compute the average over the running time for all possible input values.\n",
    "in the linear search, the number of comparisons at all positions would be 1 if the element to be searched was found at the $0^{th}$ index; \n",
    "and similarly, the number of comparisons would be 2, 3, and so forth, up to n, respectively, \n",
    "for elements found at the $1, 2, 3, ... ( n -1)$ index positions.\n",
    "\n",
    "The average-case running time will be $T(n) = \\frac{1+2+3..n} {n} =  \\frac{n(n+1)} {2n}$\n",
    "\n",
    "In the example above, the input data is organized in such a way that it takes its minimum running time to execute the given algorithm.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Space Complexity </b>\n",
    "\n",
    "The space complexity of the algorithm estimates the memory requirement to execute it on a computer to produce the output as a function of input data. The memory space requirement of an algorithm is one of the criteria used to decide how <b>efficient</b> it is.\n",
    "\n",
    "Given two algorithms to solve a given problem, with all other requirements being equal, then the algorithm that requires less memory can be considered more efficient.\n",
    "\n",
    "When the <b>input size becomes large enough</b>, the order of growth also becomes important, in such situations, we study the <b>asymptotic efficency of algorithms</b>.\n",
    "\n",
    "\n",
    "In the code below, the algorithm will require allocating memory for the number of items in the input list. Say the number of elements in the input is n, then the space requirement increases with the input size, therefore, the space complexity of the algorithm becomes $O(n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 25, 64]\n"
     ]
    }
   ],
   "source": [
    "# For computing the space complexity, consider the following example,\n",
    "# in which, given a list of integer values,\n",
    "# the function returns the square value of the corresponding integer number. \n",
    "def squares(n):\n",
    "    square_numbers = []\n",
    "    for number in n:\n",
    "        square_numbers.append(number * number)\n",
    "    return square_numbers\n",
    "nums = [2, 3, 5, 8 ]\n",
    "print(squares(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Asymptotic Notation </b></center>\n",
    "In asymptotic analysis, we analyze the efficiency of algorithms for large input sizes considering the higher order of growth and ignoring the multiplicative constants and lower-order terms.\n",
    "To analyze the time complexity of an algorithm, the <u>rate of growth (order of growth)</u> is very important when the input size is large. When the input size becomes large, we only consider the higher order terms and ignore the insignificant terms.\n",
    "\n",
    "We compare two algorithms with respect to  <u>input size</u> rather  than the actual runtime and measure how the time taken increases with an increased input size. The algorithm which is more efficient asymptotically is generally considered a better algorithm as compared to the other algorithm\n",
    "\n",
    "The following asymptotic notations are commonly used to calculate the running time complexity of an algorithm:\n",
    "- <b> $\\Theta$ notation </b> : It denotes the worst-case running time complexity with a tight bound.\n",
    "- <b> $Ο$ notation </b>: It denotes the worst-case running time complexity with an upper bound, which ensures that the function never grows faster than the upper bound.\n",
    "- <b>  $\\Omega$ notation </b>: It denotes the lower bound of an algorithm’s running time. It measures the best amount of time to execute the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> $\\Theta$ Theta Notation </b></center>\n",
    "\n",
    "the following function characterizes the worst-case running time for the fist example: $T(n) = c1 + c3 * n + c5 * n$\n",
    "Here, for a large input size, the worst-case running time will be $\\Theta(n)$. We usually consider one algorithm to be more efficient than another if its worst-case running time has a lower order of growth. \n",
    "\n",
    "Theta notation $(\\Theta)$ denotes the worst-case running time for an algorithm with a tight bound. For a give function $F(n)$, the asymptotic worst-case running time complexity can be defined as follows.\n",
    "\n",
    "<b> $T(n) = \\theta(F(n))$ </b>\n",
    "\n",
    "if there exist constants $n_0, c_1, c_2$ such that: $0 \\leq c_1(F(n)) \\leq T(n) \\leq c_2(Fn))$ for all $n \\geq 0$\n",
    "\n",
    "The function T(n) belongs to a set of function $\\Theta(F(n))$ if there exists positive constants $c_1$ and $c_2$ such that the value of $T(n)$ always lie in between $c_1F(n)$ and $c_2F(n)$ for all large values of $n$. If this condition is true, then we say $F(n)$ is asymptotically tight bound for $T(n)$.\n",
    "\n",
    "<center><img src=\"./img/1.png\" width=\"300\"/></center>\n",
    "\n",
    "So, the theta notation provides a tight bound for the time complexity of an algorithm.\n",
    "Remember that theta notation is asymptotically bound from the <b> upper and lower sides of the function <b>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Big $O$ Notation </b></center>\n",
    "\n",
    "<i> Why is it important? </i>\n",
    "\n",
    "Suppose we need to compare two algorithms we will see later (simple search and binary search).\n",
    "The problem is, the run times for binary search and simple search don’t grow at the same rate.\n",
    "\n",
    "That is, as the number of items increases, binary search takes a little more time to run. \n",
    "But simple search takes a lot more time to run. So as the list of numbers gets bigger, binary search suddenly becomes a lot faster than simple search. \n",
    "\n",
    "The researcher thought binary search was 15 times faster than simple search, but that’s not correct. If the list has 1 billion items, it’s more like 33 million times faster. \n",
    "<center><img src=\"./img/11.png\" width=\"350\"/></center>\n",
    "That’s why it’s not enough to know how long an algorithm takes to run—you need to know how the running time increases as the list size increases. That’s where Big O notation comes in.\n",
    "\n",
    "Big O notation tells you how fast an algorithm is. For example, suppose you have a list of size n. Simple search needs to check each element, so it will take n operations. \n",
    "\n",
    "The run time in Big O notation is $O(n)$, it lets you compare the number of operations. It tells you how fast the algorithm grows.\n",
    "\n",
    "<u> In detail </u>\n",
    "\n",
    "Big O notation characterizes the worst-case running time complexity, which is only the asymptotic upper bound of the function. Big O notation is defined as follows. Given a function $F(n)$, the $T(n)$ is a Big O of function $F(n)$, and we define this as follows:\n",
    "$T(n) = O(F(n))$\n",
    "\n",
    "if there exist constants $n_0$ and $c$ such that:\n",
    "$T(n) \\leq c(F(n))$ for all $n \\geq n_0$\n",
    "\n",
    "In Big O notation, a constant multiple of $F(n)$ is an asymptotic upper bound on $T(n)$, and the positive constants $n_0$ and $c$ should be in such a way that all values of n greater than $n_0$ always lie on or below function $c*F(n)$.\n",
    "\n",
    "Moreover, we only care what happens at higher values of $n$. The variable $n_0$ represents the threshold below which the rate of growth is not important.\n",
    "\n",
    "The plot shown in Figure shows a graphical representation of function $T(n)$ with a varying value of $n$.\n",
    "\n",
    "<center><img src=\"./img/2.png\" width=\"300\"/></center>\n",
    "\n",
    "In O notation, $O(F(n))$ is really a set of functions that includes all functions with the same or smaller rates of growth than $F(n)$.\n",
    "For example, $O(n^2)$ also includes $O(n)$, $O(log n)$, and so on\n",
    "\n",
    "<center>\n",
    "    <img src=\"./img/3.png\" width=\"200\" style=\"display:inline\"/>\n",
    "    <img src=\"./img/12.png\" width=\"500\" style=\"display:inline\"/>\n",
    "</center>\n",
    "\n",
    "Using Big O notation, the running time of an algorithm can be computed by analyzing the structure of the algorithm. For example, a double nested loop in an algorithm will have an upper bound on the worst-case running time of $O(n^2)$, since the values of $i$ and $j$ will be at most $n$, and both the loops will run $n^2$ times as shown in the below example code:\n",
    "\n",
    "```python\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print(\"This will have upper bound on 0(n^2)\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u> Example Exercises using the O notation: </u>\n",
    "1- <i> Find the upper bound for the function: $T(n) = 2n + 7$ </i>\n",
    "\n",
    "<!-- Solution: Using O notation, the condition for the upper bound is: $T(n) \\leq c * F(n)$ \n",
    "This condition holds true for all values of $n > 7$ and $c=3$. $2n + 7 \\leq 3n$. \n",
    "This is true for all values of $n$, with $c=3, n_0 = 7,   T(n) = 2n+7 = O(n)$ -->\n",
    "Solution \n",
    "\n",
    "In this case, we're looking for a function $(g(n))$ such that $(T(n) = 2n + 7)$ is $(O(g(n))$. \n",
    "\n",
    "The idea is to find a function that grows at the same rate or faster than $(T(n))$ for sufficiently large values of $(n)$.\n",
    "\n",
    "For this specific function $(T(n) = 2n + 7)$, the highest order term is $2n$. \n",
    "In Big-O notation, we often drop constant factors, so $(T(n))$ is $(O(n))$.\n",
    "\n",
    "So, the upper bound is: $T(n) = O(n)$.\n",
    "\n",
    "Explanation:\n",
    "- The term $2n$ dominates the growth of the function as $n$ becomes large.\n",
    "- We ignore the constant factor (2) in Big-O notation because it doesn't affect the overall growth rate as $n$ approaches infinity.\n",
    "- The \"+ 7\" part contributes to the function's growth, but it becomes relatively insignificant as $n$ becomes large compared to the $2n$ term.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2- <i> Find $F(n)$ for functions $T(n) = 2n+5$ such that $T(n) = O(F(n))$ </i>\n",
    "\n",
    "Solution \n",
    "\n",
    "For the function $T(n) = 2n + 5$, the highest order term is $2n$.\n",
    " In Big-O notation, we often drop constant factors, so $T(n)$ is $O(n)$.\n",
    "\n",
    "Therefore, you can choose $F(n)$ to be any function that grows at the same rate or faster than $O(n)$. \n",
    "\n",
    "A common choice would be $F(n) = n$ or any function that grows faster than linear, like $F(n) = n^2$, $F(n) = 2n$, etc.\n",
    "\n",
    "So, one possible solution is $F(n) = n$.\n",
    "\n",
    "Explanation:\n",
    "- The term $2n$ dominates the growth of the function as $n$ becomes large.\n",
    "- We ignore the constant factor (2) in Big-O notation because it doesn't affect the overall growth rate as $n$ approaches infinity.\n",
    "- The \"+ 5\" part contributes to the function's growth, but it becomes relatively insignificant as $n$ becomes large compared to the $2n$ term.\n",
    "\n",
    " <!-- Solution: Using O notation, the condition for the upper bound is: $T(n) \\leq c * F(n)$.\n",
    " \n",
    " Since, $2n+5 \\leq 3n$, for all $n \\geq 5$\n",
    "\n",
    " The condition is true for $c=3, n_0=5$.\n",
    "\n",
    "  $2n + 5 \\leq O(n)$\n",
    "  \n",
    "   $F(n) = n$ -->\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - <i> Find $F(n)$ for the function $T(n) = n^2 +n$, such that $T(n) = O(F(n))$. </i>\n",
    "\n",
    "Solution: Using O notation, since, $n^2+ n ≤ 2n^2$, for all $n ≥ 1$ (with $c = 2, n_0=2$) \n",
    "\n",
    "$n^2+ n ≤ O(n^2) $\n",
    "\n",
    "$ F(n) = n^2$. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - <i> Prove that $f(n) =2n^3 - 6n ≠ O(n^2)$. </i>\n",
    "\n",
    "Solution: Clearly, $2n^3-6n ≥ n^2$, for $n ≥ 2$. So it cannot be true that $2n^3 - 6n ≠ O(n^2)$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - <i> Prove that: $20n^2+2n+5 = O(n^2)$. </i>\n",
    "\n",
    "Solution: It is clear that: $20n^2+2n+5 <= 21n^2$ for all $n > 4$ (let $c = 21$ and $n_0 = 4$)\n",
    "\n",
    " $n^2 > 2n + 5$ for all $n > 4$ \n",
    " \n",
    " So, the complexity is $O(n^2)$. \n",
    " \n",
    " \n",
    " \n",
    " So, Big-O notation provides an upper bound on a function, which ensures that the function never grows faster than the upper-bounded function. In the next section, we will discuss Omega notation.\n",
    "\n",
    " <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> $\\Omega$ Omega Notation </b></center>\n",
    "Omega notation (Ω) describes an asymptotic <b>lower bound</b> on algorithms.\n",
    "It computes the best-case runtime complexity of the algorithm. The $Ω$ notation $(Ω(F(n))$ is a set of functions in such a way that there are positive constants $n_0$ and $c$ such that for all values of $n$ greater than $n_0$, $T(n)$ always lies on or above a function to $c*F(n)$.\n",
    "\n",
    "$T(n) = Ω (F(n))$\n",
    "\n",
    "If constants $n_0$ and $c$ are present, then:\n",
    "$0 \\leq c(F(n)) \\leq T(n)$, for all $n \\geq n_0$\n",
    "\n",
    "It can be observed from the figure that the value of $T(n)$ always lies above $cF(n)$ for values of $n$ greater than $n_0$.\n",
    "\n",
    "<center><img src=\"./img/4.png\" width=\"300\"/></center>\n",
    "\n",
    "If the running time of an algorithm is $Ω(F(n))$, it means that the running time of the algorithm is at least a constant multiplier of $F(n)$ for sufficiently large values of input size $(n)$. \n",
    "The $Ω$ notation gives a lower bound on the best-case running time complexity of a given algorithm. It means that the running time for a given algorithm will be at least $F(n)$ without depending upon the input.\n",
    "\n",
    "\n",
    "The $Ω$ notation is used to describe that at least a certain amount of running time will be taken by an algorithm for a large input size. In the next section, we will discuss amortized analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Exercises using the Omega notation:\n",
    "1- <i> Find $F(n)$ for the function $T(n) =2n^2 +3$ such that $T(n) = Ω(F(n))$. </i>\n",
    "\n",
    "Solution:\n",
    "\n",
    "$c*F(n) \\leq T(n)$\n",
    "\n",
    "This condition holds true for all values of $n$ greater than 0, and $c=1$\n",
    "\n",
    "$0 \\leq cn^2 \\leq 2n^2 + 3$, for all $n \\geq 0$\n",
    "\n",
    "$2n^2 + 3 = \\Omega (n^2)$\n",
    "\n",
    "$F(n) = n^2$\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- <i> Find the lower bound of $T(n) =3n^2$</i>\n",
    "\n",
    "Solution: \n",
    "\n",
    "$c*F(n) \\leq T(n)$\n",
    "\n",
    "Consider $0 \\leq cn^2 \\leq 3n^2$. The condition for $\\Omega$ notation holds true  for all values of n greater than 1, anc c=2.\n",
    "\n",
    "$cn^2 \\leq 3n^2$ (for $c=2$ and $n_0 = 1$)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- <i> Prove that $3n = Ω(n)$. </i>\n",
    "\n",
    "Solution\n",
    "\n",
    "$c*F(n) \\leq T(n)$\n",
    "\n",
    "Consider $0 \\leq c*n \\leq 3n$. The condition for $\\Omega$ notation holds true for all values of n greater than 1, and $c=1$.\n",
    "\n",
    "$cn^2 \\leq 3n^2$ (for $c=2$ and $n_0=1$)\n",
    "\n",
    "$3n = \\Omega(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Amortized Analysis: </b></center>\n",
    "In the amortized analysis of an algorithm, we average the time required to execute a sequence of operations with all the operations of the algorithm, is important when we are not interested in the time complexity of individual operations but we are interested in the average runtime of sequences of operations.\n",
    "\n",
    "We analyze algorithms considering both the costly and less costly operations in order to analyze all the sequences of operations. \n",
    "So, amortized analysis is the average performance of each operation in the worst case considering the cost of the complete sequence of all the operations.\n",
    "\n",
    "There are three commonly used methods for amortized analysis:\n",
    "- Aggregate analysis: the ammortized cost is the average cost of all the sequences of operations\n",
    "- The accounting method: we assign an amortized cost to each operation.\n",
    "- The potential method: similar to the accounting method, but we impose an extra charge to early operations that may be used later in the sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Composing Complexity Classes: Running time complexity of different functions </b></center>\n",
    "complexity classes are used to classify problems based on the amount of computational resources required to solve them. These resources may include time, space, or other factors. Composing complexity classes involves combining or relating different classes to analyze the complexity of more complex computational tasks.\n",
    "\n",
    "The goal is to analyze the combined statements in a function or method to understand the total time complexity of executing several operations.\n",
    "\n",
    "<u>EXAMPLE</u> \n",
    "\n",
    "For example, consider the two operations of inserting an element into a list and then sorting that list.\n",
    "\n",
    "Assuming that inserting an item occurs in $O(n)$ time, and sorting in $O(nlogn)$ time, then we can write the total time complexity as $O(n + nlogn)$; that is, we bring the two functions inside the $O(...)$, as per Big O computation.\n",
    " \n",
    "Considering only the highest-order term, the final worst-case complexity becomes $O(nlogn)$.\n",
    "\n",
    "<u> If we repeat an operation, for example in a while loop, then we multiply the complexity class by the number of times the operation is carried out </u>\n",
    "\n",
    "\n",
    "The time complexity of the below code becomes:\n",
    "\n",
    " $O(n^2) * O(n) = O(n*n^2) = O(n^3)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose the function f(n) has a time complexity of O(n^2)\n",
    "# and it is executed n times i a for loop:\n",
    "for i in range(n):\n",
    "    f(....)\n",
    "    \n",
    "# The time complexity is O(n^3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A <u>single nested loop</u>, that is, one loop nested inside another loop, will run $n^2$ times, such as in the following code:\n",
    "\n",
    "So if each execution of the statement takes constant time, $c$, i.e. $O(i)$, executed $n * n$ times, we can express the running time as follows:\n",
    "\n",
    "$c * n * n = c * n^2 = O(n^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        #statements\n",
    "        \n",
    "# running time c * n * n = c * n^2 = O(n^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consecutive statements within <u>nested loops</u>, we add the time complexities of each statement and multiply by the number of times the statement is executed—as in the following code.\n",
    "\n",
    "This can be written as: $c^1n + c^2 * n^2 = O(n^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(n):\n",
    "    for i in range(n): #execute n times\n",
    "        print(i)       # c1 \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            print(j)   # c1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define (base 2) logarithmic complexity, reducing the size of the problem by half, in constant time. For example in the following code.\n",
    "\n",
    "Notice that $i$ is doubling in each iteration.\n",
    "\n",
    "If we assume that the loop has $k$ iterations, then the value of $n$ will be $2n$. We can write this as follows:\n",
    "\n",
    "<center><img src=\"./img/5.png\" width=\"120\"/></center>\n",
    "\n",
    "\n",
    "From this, the worst-case runtime complexity of the above code is equal to $O(log(n))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1 \n",
    "while i <= n:\n",
    "    i = i*2\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Computing the running time complexity of an algorithm </b></center>\n",
    "Computing the running time complexity of an algorithm involves analyzing how the algorithm's running time grows with respect to the size of its input. The goal is to express this relationship using big O notation, which describes the upper bound on the growth rate of the algorithm's running time.\n",
    "\n",
    "Here are the general steps for computing the time complexity of an algorithm:\n",
    "\n",
    "1. **Identify the Basic Operations:**\n",
    "   - Determine the fundamental operations that contribute the most to the running time.\n",
    "   - These operations are usually the dominant factors in the algorithm's time complexity.\n",
    "\n",
    "2. **Count the Operations:**\n",
    "   - Analyze how many times each basic operation is executed in terms of the input size.\n",
    "   - Express this count as a function of the input size.\n",
    "\n",
    "3. **Simplify the Expression:**\n",
    "   - Simplify the expression obtained in the previous step by focusing on the most significant terms.\n",
    "   - Drop lower-order terms and constant factors.\n",
    "\n",
    "4. **Express in Big O Notation:**\n",
    "   - Use big O notation to describe the upper bound of the simplified expression.\n",
    "   - The result is often written in the form $O(f(n))$, where $f(n)$ is a function representing the growth rate.\n",
    "\n",
    "Here's a simple example to illustrate the process:\n",
    "\n",
    "```python\n",
    "def exampleAlgorithm(arr):\n",
    "    # Basic operation: Comparison in a loop\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(arr)):\n",
    "            if arr[i] < arr[j]:\n",
    "                # Basic operation: Swap elements\n",
    "                arr[i], arr[j] = arr[j], arr[i]\n",
    "\n",
    "# Time complexity analysis:\n",
    "# - Two nested loops, each of size n (where n is the length of the input array).\n",
    "# - Inside the inner loop, there is a constant-time operation (swap).\n",
    "\n",
    "# Counting operations: O(n^2) comparisons + O(n^2) swaps\n",
    "# Simplify: O(n^2)\n",
    "\n",
    "# Time complexity: O(n^2)\n",
    "```\n",
    "\n",
    "In this example, the time complexity of the algorithm is $O(n^2)$, where $n$ is the size of the input array. The nested loops contribute to the quadratic growth in the running time.\n",
    "\n",
    "It's important to note that the time complexity analysis provides an upper bound on the growth rate, and the actual running time might be better than the worst-case scenario predicted by big O notation. Additionally, constant factors and lower-order terms are often ignored in big O notation, focusing on the dominant factors that determine the growth rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Exercises </u>\n",
    "\n",
    "<i> 1- Find the worst-case runtime complexity of the following Python snippet: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop will run n times\n",
    "for i in range(n):\n",
    "    print(\"data\") #constant time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution\n",
    "\n",
    "The runtime for a loop, in general, takes the time taken by all statements in the loop, multiplied by the number of iterations. Here, total runtime is defined as follows: \n",
    "\n",
    "\n",
    "$T(n) =$ constant time $(c) * n = c*n = O(n)$\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 2 - Find the time complexity of the following Python snippet: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    for j in range(n): # This loop will also run for n times \n",
    "        print(\"run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution\n",
    "\n",
    "$O(n^2)$. \n",
    "The print statement will be executed $n^2$ times, n times for the inner loop, and, for each iteration of the outer loop, the inner loop will be executed.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 3 - Find the time complexity of the following Python snippet: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print(\"run fun\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution\n",
    "\n",
    "The worst-case complexity will be $O(n)$ since the print statement will run n times because the inner loop executes only once due to a break statement.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 4 - Find the time complexity of the following Python snippet: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(n):\n",
    "    for i in range(n):\n",
    "        print(\"data\") #constant time \n",
    "    #outer loop execute for n times \n",
    "    for i in range(n):\n",
    "        for j in range(n): #inner loop execute n times \n",
    "            print(\"run fun\") #constant time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution\n",
    "\n",
    "Here, the print statements will execute n times in the first loop and $n^2$ times for the second nested loop. \n",
    "\n",
    "Here, the total time required is defined as the following: \n",
    "\n",
    "$T(n) =$ constant time $(c_1) * n + c_2*n*n c_1 n + c_2 n^2 = O(n^2)$\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 5 - Find the time complexity of the following Python snippet: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n == 0: #constant time \n",
    "    print(\"data\")\n",
    "else: \n",
    "    for i in range(n): #loop run for n times \n",
    "        print(\"structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: $O(n)$.\n",
    " Here, the worst-case runtime complexity will be the time required for the execution of all the statements; that is, the time required for the execution of the if-else conditions, and the for loop. The time required is defined as the following: $T(n) = c_1 + c_2 n = O(n)$\n",
    "\n",
    " <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 6 - Find the time complexity of the following Python snippet: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "j=0 \n",
    "while i*i < n:\n",
    "    j = j +1\n",
    "    i = i+1\n",
    "    print(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "$O(\\sqrt{n})$. The loop will terminate based on the value of i; the loop will iterate based on the condition:\n",
    "\n",
    "$i^2 \\leq n$\n",
    "\n",
    "$T(n) = O(\\sqrt{n})$\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> 7 - Find the time complexity of the following Python snippet: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in range(int(n/2), n):\n",
    "    j=1 \n",
    "    while j+n/2 <= n:\n",
    "        k=1 \n",
    "        while k < n:\n",
    "            k *= 2\n",
    "            print(\"data\")\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "Here, the outer loop will execute $n/2$ times, the middle loop will also run $n/2$ times, and the innermost loop will run for $log(n)$ time. So, the total running time complexity will be $O(n*n*logn): O(n^2logn)$\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other exercises on Agarwal book pag 86.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
