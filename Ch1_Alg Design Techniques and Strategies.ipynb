{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b> Algorithm Design </b> </center>\n",
    "\n",
    "Rules for finding the optimal solution for a computing problem: \n",
    "1. Formulate the problem clearly \n",
    "2. Identify the appropriate algorithm design technique based on the structure of the problem for an efficient solution\n",
    "\n",
    "There are several algorithm paradigms as follows: \n",
    "- Recursion \n",
    "- Divide and conquer \n",
    "- Dynamic programming \n",
    "- Greedy algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Recursion </b></center>\n",
    "\n",
    "A recursive algorithm calls itself repeatedly in order to solve the problem until a certain condition is fulfilled. Each recursive call itself spins off other recursive calls. A recursive function can be in an infinite loop; therefore, it is required that each recursive function adheres to certain properties. \n",
    "\n",
    "At the core of a recursive function are two types of cases: \n",
    "1. <b>Base cases</b>: These tell the recursion when to terminate, meaning the recursion will be stopped once the base condition is met\n",
    "2. <b>Recursive cases</b>: The function calls itself recursively, and we progress toward achieving the base criteria\n",
    "\n",
    "<b> The 3 laws of recursion </b>\n",
    "- A recursive algorithm must have a base case\n",
    "- A recursive algorithm must call itself, recursively\n",
    "- A recursive algorithm must move towards the base case\n",
    "\n",
    "\n",
    "When you write a recursive function, you have to tell it when to stop recursing. That’s why every recursive function has two parts: the base case, and the recursive case. \n",
    "The recursive case is when the function calls itself. The base case is when the function doesn’t call itself again ... so it doesn’t go into an infinite loop.\n",
    "For example:\n",
    "```python\n",
    "def countdown(i):\n",
    "    print i\n",
    "    if i<= 0:   # Base case\n",
    "        return\n",
    "    else:       # Recursive case\n",
    "        countdown (i-1)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<u> Example</u> with calculating factorials $n!$\n",
    "Where $n!$ is equal to 1 if $n=1$ else $n(n-1)$\n",
    "\n",
    "\n",
    "The recursive factorial algorithm defines two cases: the base case when n is zero (the terminating condition) and the recursive case when n is greater than zero (the call of the function itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "def factorial(n): # test for a base case \n",
    "    if n == 0: \n",
    "        return 1 \n",
    "    else: # make a calculation and a recursive call \n",
    "        return n*factorial(n-1) \n",
    "print(factorial(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loop continues until we reach the factorial of 0 , which returns 1 . Now, each function returns the value to finally compute $1*1*2*3*4=24$, which is the final output of the function.\n",
    "\n",
    "<center><img src=\"./img/6.png\" width=\"200\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Another example of recursion </u>\n",
    "\n",
    "Suppose you’re digging through your grandma’s attic and come across a mysterious locked suitcase.\n",
    "Grandma tells you that the key for the suitcase is probably in this other box.\n",
    "This box contains more boxes, with more boxes inside those boxes. The key is in a box somewhere. What’s your algorithm to search for the key? Think of an algorithm before you read on.\n",
    "\n",
    "Here is one approach :\n",
    "<center><img src=\"./img/19.png\" width=\"200\"/></center>\n",
    "\n",
    "```python\n",
    "def look_for_key(main_box):\n",
    " \"\"\"This approach is without recursion\"\"\"\n",
    " pile = main_box.make_a_pile_to_look_through()\n",
    " while pile is not empty:\n",
    "   box = pile.grab_a_box()\n",
    "   for item in box:\n",
    "    if item.is_a_box():\n",
    "     pile.append(item) \n",
    "    elif item.is_a_key():\n",
    "     print \"found the key!\"\n",
    "```\n",
    "\n",
    "Here is another approach:\n",
    "<center><img src=\"./img/18.png\" width=\"200\"/></center>\n",
    "\n",
    "```python\n",
    "def look_for_key(main_box):\n",
    " \"\"\"This approach uses recursion\"\"\"\n",
    "def look_for_key: \n",
    "  for item in box:\n",
    "     if item.is_a_box():\n",
    "       look_for_key(item) # Recursion!\n",
    "     elif item.is_a_key(): \n",
    "      print “found the key!”\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<u>Another Example of recursion</u>\n",
    "\n",
    "These two functions below work together to find the minimum value in a list `A` using recursion.\n",
    "\n",
    "The `minrec(A, i)` function is a recursive function that finds the minimum value in the list `A` up to the index `i`. Here's how it works:\n",
    "\n",
    "- If `i` is 0, it returns the first element of the list `A` because there's only one element to consider.\n",
    "- If `i` is not 0, it finds the minimum between the `i`-th element of `A` and the minimum value in the list up to the index `i-1`. It finds the latter by recursively calling itself with `i-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 0 7\n",
      "Start 0 3\n",
      "Start 0 1\n",
      "Start 0 0\n",
      "Res: 2\n",
      "End 0 0\n",
      "Start 1 1\n",
      "Res: 4\n",
      "End 1 1\n",
      "COMPARE\n",
      "End 0 1\n",
      "Start 2 3\n",
      "Start 2 2\n",
      "Res: 1\n",
      "End 2 2\n",
      "Start 3 3\n",
      "Res: 3\n",
      "End 3 3\n",
      "COMPARE\n",
      "End 2 3\n",
      "COMPARE\n",
      "End 0 3\n",
      "Start 4 7\n",
      "Start 4 5\n",
      "Start 4 4\n",
      "Res: 6\n",
      "End 4 4\n",
      "Start 5 5\n",
      "Res: 8\n",
      "End 5 5\n",
      "COMPARE\n",
      "End 4 5\n",
      "Start 6 7\n",
      "Start 6 6\n",
      "Res: 9\n",
      "End 6 6\n",
      "Start 7 7\n",
      "Res: 12\n",
      "End 7 7\n",
      "COMPARE\n",
      "End 6 7\n",
      "COMPARE\n",
      "End 4 7\n",
      "COMPARE\n",
      "End 0 7\n"
     ]
    }
   ],
   "source": [
    "## Another Example of recursion calculating the minimum of a list\n",
    "L = [2,4,1,3,6,8,9,12]\n",
    "\n",
    "def minrec(A, i, j):\n",
    "    #print(\"A: \", A, \"i:\",i,\"j:\", j)\n",
    "    \"\"\"Returns the minimum of the elements between i and j, both included\"\"\"\n",
    "    print(\"Start\", i, j) #indeces\n",
    "    if i == j:\n",
    "        res = A[i]\n",
    "        print(\"Res:\", res)\n",
    "    else:\n",
    "        m = (i+j)//2\n",
    "        res = min(minrec(A, i, m), minrec(A, m+1, j))\n",
    "        print(\"COMPARE\") \n",
    "    print(\"End\", i, j)\n",
    "    return res\n",
    "\n",
    "def mymin(A):\n",
    "    return minrec(A, 0, len(A)-1)\n",
    "\n",
    "m = mymin(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Divide and Conquer </b></center>\n",
    "\n",
    "The divide-and-conquer paradigm divides a problem into smaller sub-problems, and then solves these; finally, it combines the results to obtain a global, optimal solution\n",
    "\n",
    "More specifically, in divide-and-conquer design, the problem is divided into two smaller sub-problems, with each of them being solved recursively. The partial solutions are merged to obtain a final solution.\n",
    "\n",
    "- <b> Divide </b>: break the problem in smaller and indipendent sub-problems\n",
    "- <b> Impera </b>: Solve the sub-problems recursively\n",
    "- <b> Combine </b>: \"merge\" the solutions of subproblems\n",
    "\n",
    "Some examples of the divide-and-conquer design technique are: \n",
    "- Binary search \n",
    "- Merge sort \n",
    "- Quick sort Algorithm for fast multiplication\n",
    "- Strassen’s matrix multiplication \n",
    "- Closest pair of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Binary Search </b></center>\n",
    "\n",
    "This algorithm is based on the divide-and-conquer design technique and is used to find a given element from a sorted list of elements.\n",
    "Its input is a sorted list of elements (explain later why it needs to be sorted).\n",
    "If an element you’re looking for is in that list, binary search returns the position where it’s located. Otherwise, binary search returns null.\n",
    "\n",
    "It first compares the search element with the middle element of the list; if the search element is smaller than the middle element, then the half of the list of elements greater than the middle element is discarded; the process repeats recursively until the search element is found or we reach the end of the list. It is important to note that in each iteration, half of the search space is discarded, which improves the performance of the overall algorithm because there are fewer elements to search through.\n",
    "\n",
    "<u> An example </u>\n",
    "\n",
    "Suppose you’re searching for a person in the phone book (what an oldfashioned sentence!). Their name starts with K. You could start at the beginning and keep flipping pages until you get to the Ks (Simple search case). But you’re more likely to start at a page in the middle, because you know the Ks are going to be near the middle of the phone book (Binary search case).\n",
    "\n",
    "<u> An example </u>\n",
    "\n",
    "Suppose you’re looking for a word in the dictionary. The dictionary has 240,000 words. In the worst case, how many steps do you think each search will take? Simple search could take 240,000 steps if the word you’re looking for is the very last one in the book. With each step of binary search, you cut the number of words in half until you’re left with only one word.\n",
    "\n",
    "<center><img src=\"./img/8.png\" width=\"350\"/></center>\n",
    "\n",
    "\n",
    "<u> Another example with code below</u>\n",
    "\n",
    "\n",
    " we want to search for element 4 in the given sorted list of elements. The list is divided in half in each iteration; with the divide-and-conquer strategy, the element is searched $O(logn)$ times.\n",
    "<center><img src=\"./img/7.png\" width=\"350\"/></center>\n",
    "\n",
    "The Python code for searching for an element in a sorted list of elements is shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 0 End: 8 Mid: 4\n",
      "mid element > key element\n",
      "Start: 0 End: 3 Mid: 1\n",
      "mid element < key element\n",
      "Start: 2 End: 3 Mid: 2\n",
      "mid element < key element\n",
      "Start: 3 End: 3 Mid: 3\n",
      "mid element = key element, STOP the algorithm\n",
      "Result: 3\n"
     ]
    }
   ],
   "source": [
    "def binary_search(arr, start, end, key):\n",
    "    while start <= end:\n",
    "        mid = start + (end - start)//2     # create a mid point\n",
    "        print(\"Start:\", start, \"End:\", end, \"Mid:\", mid)  # print the current state\n",
    "        if arr[mid] == key:\n",
    "            print(\"mid element = key element, STOP the algorithm\")\n",
    "            return mid \n",
    "        \n",
    "        elif arr[mid] < key:\n",
    "            start = mid + 1 \n",
    "            print(\"mid element < key element\")\n",
    "            # the key element is greater than the mid point, so we need to search the right part of the array\n",
    "        else:\n",
    "            \n",
    "            end = mid - 1\n",
    "            print(\"mid element > key element\")\n",
    "            # the key element is less than the min point, so we need to search the left part of the array\n",
    "    return -1\n",
    "\n",
    "arr = [4, 6, 9, 13, 14, 18, 21, 24, 38]\n",
    "x = 13\n",
    "result = binary_search(arr, 0, len(arr)-1, x) \n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we search for 13 in the given list of elements, the output of the preceding code is 3, which is the position of the searched item. \n",
    "\n",
    "\n",
    "In the code, initially, the start and end index give the position of the first and last index of the input array $[4, 6, 9, 13, 14, 18, 21, 24, 38]$. \n",
    "The item to be searched that is stored in the variable key is firstly matched with the mid element of the array, and then we discard half of the list and search for the item in another half of the list. The process is iterated until we find the item to be searched, or we reach the end of the list, and we don’t find the element.\n",
    "\n",
    "\n",
    "Thus, we can observe that when we double the number of items in the list, the number of searches required also increments by 1. We can say this as when we have a list of length $n$, the total number of searches required will be the number of times we repeated halving the list until we are left with $1$ element plus $1$, which is mathematically equivalent to $(log_2 n + 1)$. For example, if $n=8$, the output will be 3, meaning the number of searches required will be 4. \n",
    "\n",
    "The list is divided in half in each iteration; with the divide-and-conquer strategy, the worst-case time complexity of the binary search algorithm is $O(log n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About running time:\n",
    "<center><img src=\"./img/10.png\" width=\"500\"/></center>\n",
    "\n",
    "Binary search needs $log$ $n$ operations to check a list of size $n$. What’s the running time in Big O notation? It’s $O(log n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Exercises </u>\n",
    "\n",
    "- 1.1 Suppose you have a sorted list of 128 names, and you’re searching through it using binary search. What’s the maximum number of steps it would take? \n",
    "- 1.2 Suppose you double the size of the list. What’s the maximum number of steps now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Dynamic Programming </b></center>\n",
    "\n",
    "Dynamic programming is the most powerful design technique for solving optimization problems. \n",
    "\n",
    "The basic idea of dynamic programming is based on the intuition of the divide-and-conquer technique. Here, essentially, we explore the space of all the possible solutions by decomposing the problem into a series of sub-problems and then combining the results to compute the correct solution for the large problem.\n",
    "\n",
    "Dynamic programming is used when the sub-problems are overlapping, meaning that the subproblems share sub-sub-problems. The dynamic programming technique is similar to divide and conquer in that a problem is broken down into smaller problems. However, in divide and conquer, each sub-problem has to be solved before its results can be used to solve bigger problems. In contrast, dynamic programmingbased techniques solve each sub-sub-problems only once and do not recompute the solution to an already-encountered sub-problem. Rather, it uses a remembering technique to avoid the recomputation.\n",
    "\n",
    "Two important characteristics:\n",
    "\n",
    "- <b>Optimal substructure</b>: Given any problem, if the solution can be obtained by combining the solutions of its sub-problems, then the problem is said to have an optimal substructure.\n",
    "\n",
    "- <b>Overlapping sub-problem</b>: If an algorithm has to repeatedly solve the same sub-problem again and again, then the problem has overlapping sub-problems.\n",
    "\n",
    "\n",
    "However, the difference between recursion and dynamic programming is that similar sub-problems can be solved any number of times, but in dynamic programming, we keep track of previously solved sub-problems, and care is taken not to recompute any of the previously encountered sub-problems. One property that makes a problem an ideal candidate for being solved with dynamic programming is that it has an <b>overlapping set of sub-problems</b>.\n",
    "\n",
    "\n",
    "Dynamic programming takes account of the fact that each subproblem should be solved only once, and to ensure that we never reevaluate a sub-problem, we need an efficient way to store the results of each sub-problem. \n",
    "\n",
    "The following two techniques are readily available: \n",
    "\n",
    "- <b>Top-down with memoization </b>: This technique starts from the initial problem set and divides it into small sub-problems. After the solution to a sub-program has been determined, we store the result of that particular sub-problem. In the future, when this sub-problem is encountered, we only return its pre computed result.\n",
    "\n",
    "- <b>Bottom-up approach </b>: This approach depends upon the “size” of the sub-problems. We solve the smaller sub-problems first, and then while solving a particular sub-problem, we already have a solution of the smaller sub-problems on which it depends. Each sub-problem is solved only once, and whenever we try to solve any sub-problem, solutions to all the prerequisite smaller subproblems are available, which can be used to solve it.\n",
    "\n",
    "Furthermore, the solutions to the subproblems are combined in a bo om-up fashion to arrive at the solution to the bigger sub-problem in order to recursively reach the final solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Calculating the Fibonacci Series: Recursive vs Dynamic approach </b></center>\n",
    "\n",
    "A recursive-style program to generate the sequence would be as follows.\n",
    "In this code, we can see that the recursive calls are being called in order to solve the problem. When the base case is met, the fib() function returns 1. If n is equal to or less than 1, the base case is met. If the base case is not met, we call the fib() function again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n <= 1:\n",
    "        return 1 \n",
    "    else: \n",
    "        return fib(n-1) + fib(n-2)\n",
    "for i in range(5):\n",
    "    print(fib(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the overlapping sub-problems from the recursion tree as shown in Figure 3.6 that the call to fib(1) happens twice, the call to fib(2) happens three times, and the call to fib(3) occurs twice. \n",
    "\n",
    "The return values of the same function call never change; for example, the return value for fib(2) will always be the same whenever we call it. Likewise, it will also be the same for fib(1) and fib(3). \n",
    "So, they are overlapping problems, thus, computational time will be wasted if we compute the same function again whenever it is encountered.\n",
    "\n",
    "<center><img src=\"./img/16.png\" width=\"400\"/></center>\n",
    "\n",
    "\n",
    "In dynamic programming using the memoization technique, we store the results of the computation of fib(1) the first time it is encountered. Similarly, we store return values for fib(2) and fib(3). Later, whenever we encounter a call to fib(1), fib(2), or fib(3), w\n",
    "\n",
    "simply return their respective results. The recursive tree diagram is shown\n",
    "\n",
    "<center><img src=\"./img/17.png\" width=\"400\"/></center>\n",
    "\n",
    "Thus, in dynamic programming, we have eliminated the need to compute fib(3), fib(2), and fib(1) if they are encountered multiple times.\n",
    "Dynamic programming improves the running time complexity of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate the nth Fibonacci number using dynamic programming\n",
    "def dyna_fib(n, lookup):\n",
    "    # Base case: the 0th Fibonacci number is 0\n",
    "    if n == 0:\n",
    "        return 0 \n",
    "    # Base case: the 1st Fibonacci number is 1\n",
    "    if n == 1: \n",
    "        return 1 \n",
    "    # If the nth Fibonacci number has already been calculated, return it\n",
    "    if lookup[n] is not None: \n",
    "        return lookup[n] \n",
    "    # Otherwise, calculate it by summing the (n-1)th and (n-2)th Fibonacci numbers\n",
    "    lookup[n] = dyna_fib(n-1, lookup) + dyna_fib(n-2, lookup) \n",
    "    # Return the nth Fibonacci number\n",
    "    return lookup[n]\n",
    "\n",
    "# Create a list to store the calculated Fibonacci numbers\n",
    "lookup = [None]*(1000) \n",
    "\n",
    "# Print the first 6 Fibonacci numbers\n",
    "for i in range(6): \n",
    "    print(dyna_fib(i, lookup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><b> Greedy Algorithms </b></center>\n",
    "\n",
    "<u> to be finished but not in the programme </u>\n",
    "\n",
    "Greedy algorithms often involve optimization and combinatorial problems. In greedy algorithms, the objective is to obtain the optimum solution from many possible solutions in each step.\n",
    "\n",
    "The sequence of locally optimal solutions generally approximates the globally optimal solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
